{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configurações iniciais, importação e organização das imagens que serão usadas para o treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interage com o sistema operacional, como manipular arquivos e diretórios.\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Criação de strings em base64\n",
    "import base64\n",
    "\n",
    "# Geração de números aleatórios\n",
    "import random\n",
    "\n",
    "# Funções matemáticas\n",
    "import math\n",
    "\n",
    "# Extração de conteúdos em textos\n",
    "import re\n",
    "\n",
    "# Contagem de tempo\n",
    "import time\n",
    "\n",
    "# Manipulações e tratamentos de arquivos json\n",
    "import json\n",
    "\n",
    "# Manipulação de arquivos e pastas no sistema\n",
    "import shutil\n",
    "\n",
    "# Realiza computação numérica eficiente com arrays multidimensionais e funções matemáticas avançadas.\n",
    "import numpy as np\n",
    "\n",
    "# Tratamento e manipulações de dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Geração de gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tratamento de imagens\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Criação de redes neurais\n",
    "import tensorflow\n",
    "\n",
    "# Apresentação do progresso do código\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Divisão entre dados de treino e de validação\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Manipulações e tratamentos de imagens\n",
    "import cv2\n",
    "\n",
    "import skimage.draw\n",
    "from skimage.io import imread\n",
    "#import skimage\n",
    "\n",
    "# Importa todas as funções auxiliares\n",
    "from auxiliar import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def github_para_colab(links_github: list, pasta_saida: int) -> None:\n",
    "\n",
    "  \"\"\"\n",
    "  Baixa o conteúdo dos links do GitHub para o Google Colab\n",
    "  \"\"\"\n",
    "\n",
    "  # Deleta a pasta de saída caso ela já exista\n",
    "  if os.path.exists(pasta_saida): shutil.rmtree(pasta_saida)\n",
    "\n",
    "  # Cria a pasta\n",
    "  os.mkdir(pasta_saida)\n",
    "\n",
    "  # Converte eles para um foramto baixável\n",
    "  links_github = list(map(github_to_raw, links_github))\n",
    "\n",
    "  # Percorre todos os dataframes\n",
    "  for link in links_github:\n",
    "\n",
    "    # Define o caminho onde o arquivo será baixado, além do nome do próprio arquivo\n",
    "    caminho_destino = os.path.join(pasta_saida, os.path.split(link)[1])\n",
    "\n",
    "    # Cria o comando de baixar o arquivo do repositório do GitHub\n",
    "    comando = f\"wget -O {caminho_destino} {link}\"\n",
    "\n",
    "    # Executa o comando de baixar o arquivo do repositório do GitHub\n",
    "    !{comando}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importação do Mask-RCNN e carregamento do conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Baixa o Mask-RCNN, caso ele não esteja no diretório atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pasta já existe, por isso não vai precisar baixá-la.\n"
     ]
    }
   ],
   "source": [
    "# Caso Mask_RCNN-TF2 não esteja na pasta, baixa ele do repositório do GitHub\n",
    "if (\"Mask_RCNN-TF2\" not in os.listdir()) and (\"Mask_RCNN_TF2\" not in os.listdir()):\n",
    "    !git clone https://github.com/alsombra/Mask_RCNN-TF2\n",
    "\n",
    "# Apresenta um abiso ao usuário\n",
    "else: print(\"A pasta já existe, por isso não vai precisar baixá-la.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Renomeia a pasta do Mask-RCNN, caso o nome esteja errado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você precisa renomear a pasta de `Mask_RCNN-TF2` para `Mask_RCNN_TF2` para que a importação das bibliotecas funcione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pasta já existe e já está com o nome correto.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(path = \"Mask_RCNN_TF2\"):\n",
    "\n",
    "    # Tenta renomear a pasta\n",
    "    try: os.rename(src = \"Mask_RCNN-TF2\", dst = \"Mask_RCNN_TF2\")\n",
    "\n",
    "    # Avisa para o usuário renomear a pasta manualmente\n",
    "    except: print(\"Você precisa renomear a pasta manualmente.\")\n",
    "\n",
    "else: print(\"A pasta já existe e já está com o nome correto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Instala o Mask-RCNN, caso ainda não tenha sido instalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask-RCNN já foi instalado.\n"
     ]
    }
   ],
   "source": [
    "# Caminhos que são gerados após a instalação do Mask-RCNN\n",
    "caminhos = [\n",
    "    r\"Mask_RCNN_TF2\\build\",\n",
    "    r\"Mask_RCNN_TF2\\dist\",\n",
    "    r\"Mask_RCNN_TF2\\mask_rcnn.egg-info\"\n",
    "]\n",
    "\n",
    "# Variável que contará quantas pastas de 'caminhos' existem\n",
    "somador = 0\n",
    "\n",
    "# Percorre todos as pastas da lista 'caminhos'\n",
    "for caminho in caminhos:\n",
    "\n",
    "    # Caso a pasta exista\n",
    "    if os.path.exists(path = caminho):\n",
    "\n",
    "        # 'somador' recebe mais um\n",
    "        somador += 1\n",
    "\n",
    "if somador == len(caminhos): print(\"Mask-RCNN já foi instalado.\")\n",
    "\n",
    "elif somador == 0: \n",
    "    print(\"Mask-RCNN não foi instalado, instalando agora.\")\n",
    "\n",
    "    # Instala o Mask-RCNN\n",
    "    !cd Mask_RCNN_TF2/ && python setup.py install\n",
    "\n",
    "else: print(\"Nem todas as pastas do Mask-RCNN foram instaladas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Importação das bibliotecas do Mask-RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Substitua em Mask_RCNN_TF2/mrcnn/visualize.py, esse trecho de código abaixo.``\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "``Por esse.``\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Obtém o diretório onde visualize.py está localizado\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Adiciona o diretório `mrcnn` ao sys.path\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "import utils\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "``Substitua em Mask_RCNN_TF2/mrcnn/model.py, esse trecho de código abaixo.``\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from mrcnn import utils\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "``Por esse.``\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import utils\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa as bibliotecas do MR-CNN\n",
    "from Mask_RCNN_TF2.mrcnn.config import Config\n",
    "import Mask_RCNN_TF2.mrcnn.utils as utils\n",
    "from Mask_RCNN_TF2.mrcnn import visualize\n",
    "import Mask_RCNN_TF2.mrcnn.model as modellib\n",
    "from Mask_RCNN_TF2.mrcnn.model import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Criação da classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESSA FUNÇÃO CONSIDERA CADA OBJETO DENTRO DE UMA IMAGEM\n",
    "\n",
    "class DatasetPersonalizado(utils.Dataset):\n",
    "\n",
    "    def load_object(self, dataset_dir, subset, nome_annotation=\"via_region_data.json\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Carrega um subconjunto do dataset Balloon.\n",
    "        dataset_dir: Diretorio raíz do dataset.\n",
    "        subset: Subconjunto a ser carregado: train (treinamento) ou val (validação)\n",
    "\n",
    "        EXEMPLO:\n",
    "\n",
    "        self.add_class(\"objetos\", 1, \"Balloon\")\n",
    "        self.add_class(\"objetos\", 2, \"Mobile phone\")\n",
    "        self.add_class(\"objetos\", 3, \"Ruler\")\n",
    "\n",
    "        dicionario_classe_id = {\"Balloon\": 1, \"Mobile phone\": 2, \"Ruler\": 3}\n",
    "        dicionario_id_classe = {valor: chave for chave, valor in dicionario_classe_id.items()}\n",
    "        \"\"\"\n",
    "\n",
    "        #==================================================================================================================================================\n",
    "\n",
    "        self.add_class(\"objetos\", 1, \"Mobile phone\")\n",
    "\n",
    "        dicionario_classe_id = {\"Mobile phone\": 1}\n",
    "        dicionario_id_classe = {valor: chave for chave, valor in dicionario_classe_id.items()}\n",
    "\n",
    "        #==================================================================================================================================================\n",
    "\n",
    "        # Escolhe se é o dataset de Treinamento ou Validação\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, nome_annotation)))\n",
    "        annotations = list(annotations.values())  # não precisa das dict keys\n",
    "\n",
    "        # A ferramenta VIA salva as imagens em JSON mesmo que elas não contenham nenhuma anotação. Então, pulamos as imagens não anotadas.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        contagem = 0\n",
    "        # Adiciona as imagens\n",
    "        for a in annotations:\n",
    "            # Pega as coordenadas x e y dos pontos dos poligonos que formam o contorno de cada instância do objeto.\n",
    "            # Eles são armazenadas em shape_attributes (para visualizar, abra o arquivo json)\n",
    "            # A condição if é necessária para que o código suporte anotações geradas pelas versões 1.x e 2.x da VIA.\n",
    "            if type(a['regions']) is dict:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "\n",
    "            # Caso seja uma lista\n",
    "            else:\n",
    "                polygons = [r['shape_attributes'] for r in a['regions']]\n",
    "                classe = [dicionario_classe_id[r['region_attributes']['label']] for r in a['regions']]\n",
    "\n",
    "            # A função load_mask() vai precisar do tamanho da imagem para que possa converter os polígonos em mascaras.\n",
    "            # Infelizmente, o VIA não inclui isso no JSON, então devemos ler a imagem manualmente e gerar essas máscaras.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "            contagem = contagem+1\n",
    "\n",
    "            self.add_image(\"objetos\",\n",
    "                image_id=a['filename'],  # usa o nome do arquivo como id unico da imagem\n",
    "                path=image_path,\n",
    "                classe = classe,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "        print(\"Imagens \"+subset+\": \" + str(contagem))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Gera as mascaras das instâncias para a imagem.\n",
    "       Returna:\n",
    "        masks: Uma array booleana de formato/shape [height, width, instance count] com 1 mascara por instancia.\n",
    "        class_ids: uma array de 1D contendo os IDs das mascaras das instancias.\n",
    "        \"\"\"\n",
    "        # Se não for uma imagem de conjunto de dados do balão (balloon dataset), delegue à classe ascendente.\n",
    "        image_info = self.image_info[image_id]\n",
    "        #print(image_info)\n",
    "        if image_info[\"source\"] != \"objetos\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Converte os poligonos em uma mascara bitmap com shape  [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "\n",
    "        # Agora será calculado a máscara da instância. para cada pixel da imagem, classificará como pertencente à classe ou não\n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Pega os indices dos pixels dentro dos poligonos e define eles como = 1 (cor branca), caso contrário continuará valor 0 (cor preta)\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'], mask.shape) # passamos o .shape também como 3ª parâmetro para evitar possíveis erros\n",
    "\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Retorna a mascara e a array dos IDs das classes de cada instancia.\n",
    "        # Como nesse exemplo temos uma classe apenas, retornamos uma array composta de 1s\n",
    "        # return mask.astype(bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "        return mask.astype(bool), (np.array(info['classe'], dtype=np.int32)).ravel()\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Retorna o caminho da imagem.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"objetos\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuração do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Atualização de compatibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute as 5 linhas abaixo para que não tenhamos problemas ao executar com as versões mais recentes do Tensorflow\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Configurações da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigRede(Config):\n",
    "\n",
    "  # balloon_phone_ruler\n",
    "  NAME = 'phone'\n",
    "\n",
    "  # 2\n",
    "  IMAGES_PER_GPU = 2\n",
    "\n",
    "  # 1 + (quantidade de classes), visto que o fundo da imagem também será considerado\n",
    "  NUM_CLASSES = 1 + 1\n",
    "\n",
    "  # Quantidade de imagens totais de treinamento\n",
    "  # quantidade_imagens_train = len(lista_image_path_train)\n",
    "  quantidade_imagens_train = 800\n",
    "  STEPS_PER_EPOCH = (quantidade_imagens_train // IMAGES_PER_GPU) # (Quantidade de imagens) / IMAGES_PER_GPU = 5272 / 2 = 1318\n",
    "  DETECTION_MIN_CONFIDENCE = 0.9\n",
    "  USE_MINI_MASK = False\n",
    "\n",
    "  # Recomendado deixar o tamanho 512 para execuções no Colab\n",
    "  IMAGE_MIN_DIM = 512 # 512\n",
    "  IMAGE_MAX_DIM = 512 # 512\n",
    "\n",
    "  # Quantidade de imagens totais de validação\n",
    "  # quantidade_imagens_val = len(lista_image_path_val)\n",
    "  quantidade_imagens_val = 200\n",
    "  VALIDATION_STEPS = (quantidade_imagens_val // IMAGES_PER_GPU) # 5 # (Quantidade de imagens) / IMAGES_PER_GPU = 1810 / 2 = 452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Configurações da rede neural para inferência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ConfigRede):\n",
    "  GPU_COUNT = 1\n",
    "  IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Criação de funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carrega_modelo_teste(model_path: str):\n",
    "\n",
    "  \"\"\"\n",
    "  Retorna um modelo e suas configurações com base nos pesos referenciados.\n",
    "  \"\"\"\n",
    "\n",
    "  inference_config = InferenceConfig()\n",
    "  model = modellib.MaskRCNN(mode = 'inference', config = inference_config, model_dir = model_path)\n",
    "  model.load_weights(model_path, by_name = True)\n",
    "  return model, inference_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentar_imagem(model, img, tipo_modelo, visualizar: bool = False):\n",
    "\n",
    "  resultados = model.detect([img], verbose = 0)\n",
    "  r = resultados[0]\n",
    "\n",
    "  # Define as classes que serão segmentadas\n",
    "  lista_classes = ['Background']\n",
    "  lista_classes.extend(tipo_modelo)\n",
    "\n",
    "  #===============================================================================================================================\n",
    "\n",
    "  # Apresenta a imagem original com a máscara de segmentação nos objetos identificados\n",
    "  if visualizar: visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], lista_classes, r['scores'], figsize=(12,10))\n",
    "\n",
    "  return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importação dos pesos do modelo já treinados do GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Importação da branch principal e apresenta todas as branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define se os pesos serão obtidos via GitHub\n",
    "IMPORTAR_DO_GITHUB = False\n",
    "\n",
    "# Link do repositório do GitHub\n",
    "link_github = 'https://github.com/AriBarrosFilho/Pesos_Segmentation_Balloon_Phone.git'\n",
    "\n",
    "# Pasta do Google Colab que receberá o conteúdo do repositório (A pasta será criada caso não exista)\n",
    "pasta_destino = 'pesos_treinados'\n",
    "\n",
    "#===============================================================================\n",
    "\n",
    "# Caso o usuário tenha decidido importar os pesos do GitHub\n",
    "if IMPORTAR_DO_GITHUB:\n",
    "\n",
    "  # Caso a pasta exista, deleta ela\n",
    "  if os.path.exists(pasta_destino): shutil.rmtree(pasta_destino)\n",
    "\n",
    "  # Cria o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "  comando = f\"git clone --single-branch --branch main {link_github} {pasta_destino}\"\n",
    "\n",
    "  # Executa o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "  !{comando}\n",
    "\n",
    "  #-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "  # Obtém o texto do arquivo \"nome_das_branches.txt\"\n",
    "  with open(os.path.join(pasta_destino, \"nome_das_branchs.txt\")) as f:\n",
    "    conteudo = f.read()\n",
    "\n",
    "  # Cria uma lista com o nome das branches\n",
    "  lista_branches = conteudo.splitlines()\n",
    "\n",
    "  # Destaca as branches que serão apresentada abaixo\n",
    "  print(\"\\n\", \"-\" * 100, \"\\n\", sep = \"\")\n",
    "\n",
    "  # Apresenta todas as branches do repositório\n",
    "  for i, branch in enumerate(lista_branches): print(i, branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Importação de branches específicas (Que contém pesos específicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quais branches serão importadas através de suas posições na lista\n",
    "branches = [3, 4]\n",
    "\n",
    "#===============================================================================\n",
    "\n",
    "# Caso o usuário tenha decidido importar os pesos do GitHub\n",
    "if IMPORTAR_DO_GITHUB:\n",
    "\n",
    "  # Percorre cada branch definida para ser baixada\n",
    "  for branch in branches:\n",
    "\n",
    "    # Pasta do Google Colab que receberá o conteúdo do repositório\n",
    "    pasta_destino_branch = os.path.join(pasta_destino, lista_branches[branch])\n",
    "\n",
    "    # Caso a pasta exista, deleta ela\n",
    "    if os.path.exists(pasta_destino_branch): shutil.rmtree(pasta_destino_branch)\n",
    "\n",
    "    # Cria o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "    comando = f\"git clone --branch {lista_branches[branch]} --single-branch {link_github} {pasta_destino_branch}\"\n",
    "\n",
    "    # Executa o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "    !{comando}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Recria os arquivos originais dos pesos com base nos dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso o usuário tenha decidido importar os pesos do GitHub\n",
    "if IMPORTAR_DO_GITHUB:\n",
    "\n",
    "  # Percorre cada branch definida para ser baixada\n",
    "  for branch in tqdm(branches):\n",
    "\n",
    "    # Pasta do Google Colab que receberá o conteúdo do repositório\n",
    "    pasta_destino_branch = os.path.join(pasta_destino, lista_branches[branch])\n",
    "\n",
    "    # Cria o caminho absoluto de onde estão os dataframes com strings em base64\n",
    "    caminho_completo = os.path.abspath(os.path.join(pasta_destino_branch, lista_branches[branch]))\n",
    "\n",
    "    #===============================================================================\n",
    "\n",
    "    # Junta e concatena em um único dataframe todos os dataframes\n",
    "    df_base64 = read_and_concat_parquets(caminho_completo)\n",
    "\n",
    "    # Com base em um dataframe com strings em base64, converte o arquivo para o seu formato original\n",
    "    combine_base64_and_restore(df = df_base64, output_directory = pasta_destino_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Obtém o caminho completo de todos os pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso o usuário tenha decidido importar os pesos do GitHub\n",
    "if IMPORTAR_DO_GITHUB:\n",
    "\n",
    "  # Lista que conterá o caminho absoluto de todos os arquivos possuem a extensão .h5, dentro de uma pasta\n",
    "  lista_caminho_pesos = []\n",
    "\n",
    "  # Percorre toda a pasta e suas subpastas\n",
    "  for caminho, _, arquivos in os.walk(pasta_destino):\n",
    "    for arquivo in arquivos:\n",
    "\n",
    "      # Adiciona o caminho absoluto de todos os arquivos na lista\n",
    "      lista_caminho_pesos.append(os.path.abspath(os.path.join(caminho, arquivo)))\n",
    "\n",
    "  # Realiza uma filtragem para apenas arquivos que possuem a extensão .h5\n",
    "  lista_caminho_pesos = list(filter(lambda arquivo: arquivo.endswith('.h5'), lista_caminho_pesos))\n",
    "\n",
    "  # Aviso ao usuário\n",
    "  print('Abaixo está os caminhos dos pesos disponíveis, selecione o que você deseja.', '\\n', '-' * 100, '\\n')\n",
    "\n",
    "  # Apresenta o caminho completo para cada peso importado.\n",
    "  for caminho in lista_caminho_pesos: print(caminho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Carregamento das redes neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Modelo do celular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaatus\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "# Caminho onde estão os pesos treinados\n",
    "caminho_pesos_treinados = \"pesos_treinados_local\\mask_rcnn_mobilephone_0017.h5\"\n",
    "\n",
    "#=====================================================================================================\n",
    "\n",
    "# Tenta carregar o modelo\n",
    "try:\n",
    "\n",
    "  # Carrega o modelo com base nos pesos importados\n",
    "  model_phone, inference_config_phone = carrega_modelo_teste(model_path = caminho_pesos_treinados)\n",
    "\n",
    "# Caso não seja possível carregar o modelo\n",
    "except:\n",
    "\n",
    "  # Alerta ao usuário de que houve um problema\n",
    "  print(\"DEU ALGO ERRADO, REVEJA AS CONFIGURAÇÕES DA QUANTIDADE DE CLASSES NA SEÇÃO 3.2.\")\n",
    "  model_phone, inference_config_phone = (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Modelo do balão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho onde estão os pesos treinados\n",
    "caminho_pesos_treinados = \"pesos_treinados_local\\mask_rcnn_balloon_0017.h5\"\n",
    "\n",
    "# Tenta carregar o modelo\n",
    "try:\n",
    "\n",
    "  # Carrega o modelo com base nos pesos importados\n",
    "  model_balloon, inference_config_balloon = carrega_modelo_teste(model_path = caminho_pesos_treinados)\n",
    "\n",
    "# Caso não seja possível carregar o modelo\n",
    "except:\n",
    "\n",
    "  # Alerta ao usuário de que houve um problema\n",
    "  print(\"DEU ALGO ERRADO, REVEJA AS CONFIGURAÇÕES DA QUANTIDADE DE CLASSES NA SEÇÃO 3.2.\")\n",
    "  model_balloon, inference_config_balloon = (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Modelo do celular e do balão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEU ALGO ERRADO, REVEJA AS CONFIGURAÇÕES DA QUANTIDADE DE CLASSES NA SEÇÃO 3.2.\n"
     ]
    }
   ],
   "source": [
    "# Caminho onde estão os pesos treinados\n",
    "caminho_pesos_treinados = \"NÃO VOU USAR\"\n",
    "\n",
    "# Tenta carregar o modelo\n",
    "try:\n",
    "\n",
    "  # Carrega o modelo com base nos pesos importados\n",
    "  model_balloon_phone, inference_config_balloon_phone = carrega_modelo_teste(model_path = caminho_pesos_treinados)\n",
    "\n",
    "# Caso não seja possível carregar o modelo\n",
    "except:\n",
    "  \n",
    "  # Alerta ao usuário de que houve um problema\n",
    "  print(\"DEU ALGO ERRADO, REVEJA AS CONFIGURAÇÕES DA QUANTIDADE DE CLASSES NA SEÇÃO 3.2.\")\n",
    "  model_balloon_phone, inference_config_balloon_phone = (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Criação do dicionário selecionador de modelos de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário que conterá o modelo e o nome das classes para a segmentação\n",
    "modelo_classe = {'balloon': (model_balloon, ['Bexiga']), \n",
    "                 'phone': (model_phone, [\"Celular\"]), \n",
    "                 'balloon_phone': (model_balloon_phone, ['Bexiga', 'Celular'])}\n",
    "\n",
    "id_classe = {'1': 'Bexiga', '2': 'Celular'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Importação das imagens a partir GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Importação da branch main do repositório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link do repositório do GitHub\n",
    "link_github = 'https://github.com/AriBarrosFilho/Imagens_Bexiga_Celular.git'\n",
    "\n",
    "# Pasta do Google Colab que receberá o conteúdo do repositório (A pasta será criada caso não exista)\n",
    "pasta_destino = 'imagens'\n",
    "\n",
    "# Caso o usuário não tenha as imagens e deseja baixar através do GitHub\n",
    "BAIXAR_IMAGENS_DO_GITHUB = False\n",
    "\n",
    "#===============================================================================\n",
    "\n",
    "if BAIXAR_IMAGENS_DO_GITHUB:\n",
    "\n",
    "  # Caso a pasta exista, deleta ela\n",
    "  if os.path.exists(pasta_destino): shutil.rmtree(pasta_destino)\n",
    "\n",
    "  # Cria o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "  comando = f\"git clone --single-branch --branch main {link_github} {pasta_destino}\"\n",
    "\n",
    "  # Executa o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "  !{comando}\n",
    "\n",
    "  #-------------------------------------------------------------------------------------------\n",
    "\n",
    "  # Obtém o texto do arquivo \"nome_das_branches.txt\"\n",
    "  with open(os.path.join(pasta_destino, \"nome_das_branchs.txt\")) as f:\n",
    "    conteudo = f.read()\n",
    "\n",
    "  # Cria uma lista com o nome das branches\n",
    "  lista_branches = conteudo.splitlines()\n",
    "\n",
    "  # Destaca as branches que serão apresentada abaixo\n",
    "  print(\"\\n\", \"-\" * 100)\n",
    "\n",
    "  # Apresenta a quantidade de branches (Cada branch representa uma bexiga com um peso diferente)\n",
    "  print(\"A quantidade de branches (pacotes de imagens) é:\", len(lista_branches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Importação de branches específicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define quantos pacotes de imagens serão baixados\n",
    "quantidade_pacotes = 5 # 30\n",
    "\n",
    "#========================================================================================================\n",
    "\n",
    "if BAIXAR_IMAGENS_DO_GITHUB:\n",
    "\n",
    "  # Caso a quantidade de pacotes esteja dentro da faixa permitida\n",
    "  if quantidade_pacotes <= len(lista_branches):\n",
    "\n",
    "    # Retorna os elementos da lista de branches de forma aleatória\n",
    "    lista_pacotes = random.sample(lista_branches, k = quantidade_pacotes)\n",
    "\n",
    "    # Obtém o momento inicial antes da importação das imagens\n",
    "    tempo_inicial = time.time()\n",
    "\n",
    "    # Percorre todas as branches selecionadas\n",
    "    for branch in lista_pacotes:\n",
    "\n",
    "      # Pasta do Google Colab que receberá o conteúdo do repositório (A pasta será criada caso não exista)\n",
    "      pasta_destino_branch = os.path.join(pasta_destino, branch)\n",
    "\n",
    "      # Cria o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "      comando = f\"git clone --branch {branch} --single-branch {link_github} {pasta_destino_branch}\"\n",
    "\n",
    "      # Executa o comando de clonar a branch main do repositório para uma pasta do Google Colab\n",
    "      !{comando}\n",
    "\n",
    "  # Obtém o tempo total em minutos para a importação das imagens\n",
    "  tempo_total = round((time.time() - tempo_inicial) / 60, 2)\n",
    "\n",
    "  # Obtém a quantidade média em segundos para a importação de um pacote de imagens\n",
    "  pacotes_por_segundo = round((time.time() - tempo_inicial) / len(lista_pacotes), 1)\n",
    "\n",
    "  # Destaca as branches que serão apresentada abaixo\n",
    "  print(\"\\n\", \"-\" * 100, \"\\n\")\n",
    "\n",
    "  # Apresenta ao usuário o tempo necessário para a importação das imagens\n",
    "  print(f\"Demorou {tempo_total} minutos, {pacotes_por_segundo} segundos por pacote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Cria o dataframe com os dados das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo está um exemplo de caminho relativo de uma imagem de uma bexiga com celular para exemplificar o signficado dos nomes e números.\n",
    "\n",
    "``\\imagens\\30_1990\\20241207_212143.jpg``\n",
    "\n",
    "- 1. `imagens` representa a pasta que contém as pastas com imagens de bexigas e celulares de cada peso.\n",
    "- 2. `30` representa o ID da bexiga, isto é, qual bexiga aquela imagem representa.\n",
    "- 3. `1990` peso em gramas da bexiga.\n",
    "- 4. `20241207` data que aquela imagem foi tirada -> 07/12/2024.\n",
    "- 5. `212143` horário que aquela imagem foi tirada -> 21:21:43."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasta_destino = \"imagens\"\n",
    "\n",
    "# \"/\" para Google Colab\n",
    "# \"\\\\\" para local\n",
    "divisor_caminho = \"\\\\\"\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Lista que armazenará o caminho completo das imagens válidas\n",
    "lista_caminho_arquivos = []\n",
    "\n",
    "# Percorre todas as pastas e subpastas\n",
    "for caminho, _, arquivos in os.walk(pasta_destino):\n",
    "  for arquivo in arquivos:\n",
    "\n",
    "    # Acrescenta na lista o caminho completo de todos os arquivos\n",
    "    lista_caminho_arquivos.append(os.path.abspath(os.path.join(caminho, arquivo)))\n",
    "\n",
    "# Filtra os arquivos que possuem a extensão .jpg\n",
    "lista_caminho_arquivos = list(filter(lambda x: x.endswith('.jpg') and ('balança' not in x), lista_caminho_arquivos))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Ordena a lista de acordo com o ID da bexiga\n",
    "lista_caminho_arquivos = sorted(lista_caminho_arquivos, key = lambda x: int(x.split(divisor_caminho)[-2].split('_')[0]))\n",
    "\n",
    "# Lista que armazenará o nome da imagens\n",
    "lista_imagens = list(map(lambda x: os.path.basename(x), lista_caminho_arquivos))\n",
    "\n",
    "# Lista que armazenará o ID da bexiga nas imagens\n",
    "lista_id = list(map(lambda x: int(x.split(divisor_caminho)[-2].split('_')[0]), lista_caminho_arquivos))\n",
    "\n",
    "# Lista que armazenará o peso da bexiga nas imagens\n",
    "lista_pesos = list(map(lambda x: int(x.split(divisor_caminho)[-2].split('_')[1]), lista_caminho_arquivos))\n",
    "\n",
    "# Dicionário que conterá os dados das imagens\n",
    "dicionario_dados = {'caminho': lista_caminho_arquivos, 'imagem': lista_imagens, 'id': lista_id, 'gramas': lista_pesos}\n",
    "\n",
    "# Cria um dataframe com os dados das imagens\n",
    "df_imagens = pd.DataFrame(dicionario_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Corrige a orientação de todas as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [00:57<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "def corrigir_e_exibir(diretorio_imagem: str, exibir_imagem: bool = True) -> None:\n",
    "\n",
    "    \"\"\"\n",
    "    Recebe o diretório de uma imagem, corrige a sua orientação, salva ela no lugar\n",
    "    da original, e apresenta a imagem.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verifica se o arquivo existe\n",
    "    if os.path.exists(diretorio_imagem):  \n",
    "        \n",
    "        # Corrigir a orientação com base nos metadados\n",
    "        img = Image.open(diretorio_imagem)\n",
    "        img_corrigida = ImageOps.exif_transpose(img)\n",
    "\n",
    "        # Substituir o arquivo original pelo corrigido\n",
    "        img_corrigida.save(diretorio_imagem)\n",
    "\n",
    "        # Exibir a imagem caso o usuário tenha definido\n",
    "        if exibir_imagem:\n",
    "          plt.imshow(img_corrigida)\n",
    "          plt.axis('off')\n",
    "          plt.show()\n",
    "    else:\n",
    "        print(f\"Arquivo não encontrado: {diretorio_imagem}\")\n",
    "\n",
    "# Percorre todas as imagens\n",
    "for imagem in tqdm(lista_caminho_arquivos):\n",
    "\n",
    "  # Corrige a orientação da imagem e salva ela no lugar da original\n",
    "  corrigir_e_exibir(diretorio_imagem = imagem, exibir_imagem = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Segmentação das imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Visualização para uma imagem específica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataframe abaixo representa todas as imagens que você colocou de forma estruturada na pasta `imagens`, mas nada te impede de pegar uma foto aleatória e colocar onde quiser, basta apenas guardar o seu caminho relativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caminho</th>\n",
       "      <th>imagem</th>\n",
       "      <th>id</th>\n",
       "      <th>gramas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161426.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161443.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161447.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161458.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161528.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_204949.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_204954.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_204959.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_205006.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_205019.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               caminho               imagem  \\\n",
       "0    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161426.jpg   \n",
       "1    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161443.jpg   \n",
       "2    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161447.jpg   \n",
       "3    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161458.jpg   \n",
       "4    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161528.jpg   \n",
       "..                                                 ...                  ...   \n",
       "172  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_204949.jpg   \n",
       "173  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_204954.jpg   \n",
       "174  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_204959.jpg   \n",
       "175  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_205006.jpg   \n",
       "176  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_205019.jpg   \n",
       "\n",
       "     id  gramas  \n",
       "0     1     114  \n",
       "1     1     114  \n",
       "2     1     114  \n",
       "3     1     114  \n",
       "4     1     114  \n",
       "..   ..     ...  \n",
       "172  34    3948  \n",
       "173  34    3948  \n",
       "174  34    3948  \n",
       "175  34    3948  \n",
       "176  34    3948  \n",
       "\n",
       "[177 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apresenta o dataframe com os dados das imagens\n",
    "display(df_imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta célula o usuário poderá visualizar a segmentação da imagem que ele passar, com base no objeto escolhido.\n",
    "\n",
    "O usuário definirá:\n",
    "\n",
    "* `indice`: Representa a imagem do dataframe anterior com base em seu índice.\n",
    "* `tipo`: Objeto que será segmentado, observar a célula **5.4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice da imagem\n",
    "indice = 3\n",
    "\n",
    "# Define o objeto que será segmentado\n",
    "# tipo_modelo: 'balloon', 'phone' ou 'balloon_phone'\n",
    "tipo = \"phone\"\n",
    "\n",
    "# Define se a imagem original (sem segmentações) será apresentada\n",
    "APRESENTAR_IMAGEM_ORIGINAL = False\n",
    "\n",
    "# Define se a imagem gerada (com a segmentação) será apresentada\n",
    "APRESENTAR_IMAGEM_SEGMENTADA = False\n",
    "\n",
    "#===============================================================================\n",
    "\n",
    "if df_imagens.shape[0] > indice:\n",
    "\n",
    "  # Define a imagem com base em seu caminho\n",
    "  img_teste = imread(df_imagens.loc[indice, 'caminho'])\n",
    "  # img_teste = imread(\"imagem.png\") # Você pode acrescentar um caminho qualquer de uma imagem, caso não queira usar as do dataframe\n",
    "\n",
    "  if APRESENTAR_IMAGEM_ORIGINAL:\n",
    "\n",
    "    # Mostra a imagem original\n",
    "    mostrar(img_teste)\n",
    "\n",
    "  # Apresenta a imagem com a segmentação\n",
    "  r = segmentar_imagem(model = modelo_classe[tipo][0], img = img_teste, tipo_modelo = modelo_classe[tipo][1], visualizar = APRESENTAR_IMAGEM_SEGMENTADA)\n",
    "\n",
    "# Avisa ao usuário o índice máximo permitido\n",
    "else: print(f\"O índice deve ser menor ou igual a {df_imagens.shape[0] - 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Gera uma imagem com o efeito Cut Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_imagem_segmentada_balao_celular(image_path: str, output_path: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Gera uma imagem em escala de cinza, com o balão e o celular com cores diferentes para destacar a segmentação do modelo.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Caminho da imagem quer será segmentada. \n",
    "        output_path (str): Caminho da imagem já segmentada.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dicionário que conterá o modelo e o nome das classes para a segmentação\n",
    "    modelo_classe = {'balloon': (model_balloon, ['Bexiga']), \n",
    "                    'phone': (model_phone, [\"Celular\"]), \n",
    "                    'balloon_phone': (model_balloon_phone, ['Bexiga', 'Celular'])}\n",
    "    \n",
    "    # Define os objetos que serão segmentados\n",
    "    lista_objetos = [\"balloon\", \"phone\"]\n",
    "\n",
    "    # Lista que conterá a máscara de segmentação de todos os objetos que forem passados\n",
    "    lista_mascara_segmentacao = []\n",
    "\n",
    "    # Passa por todo objeto para fazer a segmentação de cada um\n",
    "    for objeto in lista_objetos:\n",
    "\n",
    "        # Obtém a máscara de segmentação do objeto\n",
    "        r = segmentar_imagem(model = modelo_classe[objeto][0], \n",
    "                            img = imread(image_path), \n",
    "                            tipo_modelo = modelo_classe[objeto][1], \n",
    "                            visualizar = False)\n",
    "        \n",
    "        # Salva a máscara de segmentação na lista\n",
    "        lista_mascara_segmentacao.append(r)\n",
    "\n",
    "    # Aplica a máscara de segmentação na imagem e salva a nova imagem\n",
    "    highlight_objects(image_path = image_path, \n",
    "                    class1 = lista_mascara_segmentacao[1], \n",
    "                    class2 = lista_mascara_segmentacao[0], \n",
    "                    output_path = output_path, \n",
    "                    alpha = 1, \n",
    "                    intensity = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O usuário pode definir o caminho da imagem tanto pelo dataframe quanto por outro caminho da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Índice do dataframe\n",
    "indice = 3\n",
    "\n",
    "# Caminho da imagem de entrada (imagem que será segmentada)\n",
    "image_path = df_imagens[\"caminho\"][indice].split(\"future_alaatus\\\\\")[1]\n",
    "\n",
    "# Imagem de saída (com a aplicação da máscara de segmentação)\n",
    "output_path = \"imagens_geradas/imagem_cut_out.png\"\n",
    "\n",
    "gerar_imagem_segmentada_balao_celular(image_path = image_path, output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Realiza a segmentação para todas as imagens com todos os objetos e gera um dataframe com os respectivos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [21:29<00:00,  7.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Lista que armazenará a quantidade de segmentações, e a média de pixels dos objetos segmentados\n",
    "lista_resultados = []\n",
    "\n",
    "lista_info = []\n",
    "\n",
    "# Registra a chave da imagem\n",
    "indice = 0\n",
    "\n",
    "# Percorre todas as imagens\n",
    "for indice in tqdm(range(df_imagens.shape[0])):\n",
    "\n",
    "    lista_objetos = []\n",
    "\n",
    "    for tipo in [\"balloon\", \"phone\"]:\n",
    "\n",
    "        # Seleciona o modelo que realizará a segumentação\n",
    "        model = modelo_classe[tipo][0]\n",
    "    \n",
    "        # Seleciona a linha do dataframe referente ao seu índice\n",
    "        df_imagem_especifica = df_imagens.iloc[indice]\n",
    "\n",
    "        # Define a imagem\n",
    "        img = imread(df_imagem_especifica['caminho'])\n",
    "\n",
    "        # Obtém os resultados da semgentação\n",
    "        resultados = model.detect([img], verbose=0)\n",
    "        r = resultados[0]\n",
    "\n",
    "        # Apresenta quantos objetos o modelo conseguiu segmentar\n",
    "        quantidade_segmentações = r['masks'].shape[2]\n",
    "\n",
    "        # Caso tenha sido detectado pelo menos um objeto, obtém a quantidade média de pixels de todas as segmentações\n",
    "        if quantidade_segmentações != 0: media_pixels = r['masks'].sum() / quantidade_segmentações\n",
    "\n",
    "        # Caso nenhum objeto tenha sido detectado\n",
    "        else: media_pixels = 0\n",
    "\n",
    "        # Armazenará na lista a quantidade de segmentações e média de pixels respectivamente de cada objeto\n",
    "        lista_objetos.append((quantidade_segmentações, media_pixels))\n",
    "        \n",
    "    # Armazena: Índice da imagem, peso do balão (gramas), a quantidade de segmentações e a média de pixels dos objetos segmentados\n",
    "    lista_resultados.append(lista_objetos)\n",
    "    lista_info.append((df_imagens.iloc[indice][\"caminho\"], df_imagens.iloc[indice][\"imagem\"], df_imagens.iloc[indice][\"id\"], df_imagens.iloc[indice][\"gramas\"]))\n",
    "\n",
    "    indice += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizando os dados das listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deixa no final uma lista de listas de 4 elementos \n",
    "# (Quantidade de segmentações da bexiga, média de pixels da bexiga, Quantidade de segmentações do celular, média de pixels do celular)\n",
    "lista_final = []\n",
    "for linha in lista_resultados:\n",
    "    lista_tuplas = []\n",
    "    for tupla in linha:\n",
    "        lista_tuplas.extend(tupla)\n",
    "    lista_final.append(tuple(lista_tuplas))\n",
    "\n",
    "# Junta a lista que contém a quantidade e a média de pixels de cada um dos objetos, e as informações de localização da imagem, id, gramas\n",
    "lista_final_info = list(zip(lista_final, lista_info))\n",
    "\n",
    "# Deixa no final uma lista de listas de 4 elementos \n",
    "# (Quantidade de segmentações da bexiga, média de pixels da bexiga, Quantidade de segmentações do celular, média de pixels do celular)\n",
    "lista_final = []\n",
    "for linha in lista_final_info:\n",
    "    lista_tuplas = []\n",
    "    for tupla in linha:\n",
    "        lista_tuplas.extend(tupla)\n",
    "    lista_final.append(tuple(lista_tuplas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caminho_imagem</th>\n",
       "      <th>nome_imagem</th>\n",
       "      <th>id</th>\n",
       "      <th>peso_gramas</th>\n",
       "      <th>segmentacoes_bexiga</th>\n",
       "      <th>media_pixels_bexiga</th>\n",
       "      <th>segmentacoes_celular</th>\n",
       "      <th>media_pixels_celular</th>\n",
       "      <th>cm2_balao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161426.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>123911.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161443.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>685152.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161447.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>552731.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1085481.0</td>\n",
       "      <td>52.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161458.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1277467.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2492461.0</td>\n",
       "      <td>52.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20241201_161528.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>132268.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_204949.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "      <td>1</td>\n",
       "      <td>828958.0</td>\n",
       "      <td>1</td>\n",
       "      <td>207511.0</td>\n",
       "      <td>410.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_204954.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "      <td>1</td>\n",
       "      <td>2123456.0</td>\n",
       "      <td>1</td>\n",
       "      <td>487440.0</td>\n",
       "      <td>447.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_204959.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "      <td>1</td>\n",
       "      <td>3285507.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_205006.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "      <td>1</td>\n",
       "      <td>4354586.0</td>\n",
       "      <td>1</td>\n",
       "      <td>810026.0</td>\n",
       "      <td>552.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...</td>\n",
       "      <td>20250518_205019.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>3948</td>\n",
       "      <td>1</td>\n",
       "      <td>76708.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        caminho_imagem          nome_imagem  \\\n",
       "0    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161426.jpg   \n",
       "1    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161443.jpg   \n",
       "2    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161447.jpg   \n",
       "3    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161458.jpg   \n",
       "4    c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20241201_161528.jpg   \n",
       "..                                                 ...                  ...   \n",
       "172  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_204949.jpg   \n",
       "173  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_204954.jpg   \n",
       "174  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_204959.jpg   \n",
       "175  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_205006.jpg   \n",
       "176  c:\\Users\\AriosvaldoBarros\\Desktop\\future_alaat...  20250518_205019.jpg   \n",
       "\n",
       "     id  peso_gramas  segmentacoes_bexiga  media_pixels_bexiga  \\\n",
       "0     1          114                    1             123911.0   \n",
       "1     1          114                    0                  0.0   \n",
       "2     1          114                    1             552731.0   \n",
       "3     1          114                    1            1277467.0   \n",
       "4     1          114                    1             132268.0   \n",
       "..   ..          ...                  ...                  ...   \n",
       "172  34         3948                    1             828958.0   \n",
       "173  34         3948                    1            2123456.0   \n",
       "174  34         3948                    1            3285507.0   \n",
       "175  34         3948                    1            4354586.0   \n",
       "176  34         3948                    1              76708.0   \n",
       "\n",
       "     segmentacoes_celular  media_pixels_celular  cm2_balao  \n",
       "0                       0                   0.0        inf  \n",
       "1                       2              685152.5       0.00  \n",
       "2                       2             1085481.0      52.31  \n",
       "3                       2             2492461.0      52.65  \n",
       "4                       0                   0.0        inf  \n",
       "..                    ...                   ...        ...  \n",
       "172                     1              207511.0     410.34  \n",
       "173                     1              487440.0     447.48  \n",
       "174                     0                   0.0        inf  \n",
       "175                     1              810026.0     552.21  \n",
       "176                     0                   0.0        inf  \n",
       "\n",
       "[177 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define o nome das colunas\n",
    "nome_colunas = [\"segmentacoes_bexiga\", \"media_pixels_bexiga\",\n",
    "                \"segmentacoes_celular\", \"media_pixels_celular\",\n",
    "                \"caminho_imagem\", \"nome_imagem\", \"id\", \"peso_gramas\"]\n",
    "\n",
    "# Cria o dataframe\n",
    "df = pd.DataFrame(data = lista_final, columns = nome_colunas)\n",
    "\n",
    "# Altera a ordem das colunas\n",
    "df = df[['caminho_imagem', 'nome_imagem', 'id', 'peso_gramas', 'segmentacoes_bexiga', 'media_pixels_bexiga', 'segmentacoes_celular', 'media_pixels_celular']]\n",
    "\n",
    "# Os dois celulares possuem a mesma dimensão\n",
    "cm2_do_celular = 102.72\n",
    "\n",
    "# Cria uma coluna para definir a quantidade de pixels por cm2\n",
    "df[\"cm2_pixel\"] = df[\"media_pixels_celular\"] / cm2_do_celular\n",
    "\n",
    "# Obtém o cm2 do balão\n",
    "df[\"cm2_balao\"] = df[\"media_pixels_bexiga\"] / df[\"cm2_pixel\"]\n",
    "\n",
    "# Remove ac oluna \"cm2_pixel\", que agora é irrelevante para as análises\n",
    "df.drop(columns = \"cm2_pixel\", inplace = True)\n",
    "\n",
    "# Apresenta o dataframe\n",
    "display(df.round(decimals = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataframe\n",
    "df.to_parquet(\"analise_dados/dados_balao.parquet\", engine = \"pyarrow\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
